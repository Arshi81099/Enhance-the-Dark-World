{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":89760,"databundleVersionId":10486094,"sourceType":"competition"}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T08:12:16.976144Z","iopub.execute_input":"2024-12-16T08:12:16.976684Z","iopub.status.idle":"2024-12-16T08:12:18.073999Z","shell.execute_reply.started":"2024-12-16T08:12:16.976657Z","shell.execute_reply":"2024-12-16T08:12:18.073220Z"}},"outputs":[{"name":"stdout","text":"Mon Dec 16 08:12:17 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   37C    P0             26W /  250W |       0MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.transforms import Compose, ToTensor, Normalize, Resize\nfrom torchvision.utils import save_image\nimport csv\nfrom tqdm import tqdm\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport torch.nn.functional as F\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T08:12:18.076223Z","iopub.execute_input":"2024-12-16T08:12:18.076615Z","iopub.status.idle":"2024-12-16T08:12:22.270052Z","shell.execute_reply.started":"2024-12-16T08:12:18.076576Z","shell.execute_reply":"2024-12-16T08:12:22.269374Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class LowDimDataset(Dataset):\n    def __init__(self, noisy_dir, gt_dir=None, transform=None):\n        self.noisy_images = sorted([os.path.join(noisy_dir, fname) for fname in os.listdir(noisy_dir)])\n        self.gt_images = sorted([os.path.join(gt_dir, fname) for fname in os.listdir(gt_dir)]) if gt_dir else None\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.noisy_images)\n\n    def __getitem__(self, idx):\n        noisy_image = Image.open(self.noisy_images[idx]).convert(\"RGB\")\n        if self.transform:\n            noisy_image = self.transform(noisy_image)\n        \n        if self.gt_images:\n            gt_image = Image.open(self.gt_images[idx]).convert(\"RGB\")\n            if self.transform:\n                gt_image = self.transform(gt_image)\n            return noisy_image, gt_image\n        return noisy_image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T08:12:22.270984Z","iopub.execute_input":"2024-12-16T08:12:22.271329Z","iopub.status.idle":"2024-12-16T08:12:22.277838Z","shell.execute_reply.started":"2024-12-16T08:12:22.271303Z","shell.execute_reply":"2024-12-16T08:12:22.276944Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"#Transformations\ntransform = Compose([  # Ensure all images are of the same size\n    ToTensor(),\n])\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T08:12:22.278772Z","iopub.execute_input":"2024-12-16T08:12:22.279022Z","iopub.status.idle":"2024-12-16T08:12:22.289175Z","shell.execute_reply.started":"2024-12-16T08:12:22.278998Z","shell.execute_reply":"2024-12-16T08:12:22.288330Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class ResidualDenseBlock(nn.Module):\n    def __init__(self, in_channels, growth_rate=32, num_layers=5):\n        super(ResidualDenseBlock, self).__init__()\n        self.layers = nn.ModuleList()\n        total_channels = in_channels\n        for i in range(num_layers):\n            out_channels = growth_rate\n            layer = nn.Sequential(\n                nn.Conv2d(total_channels, out_channels, 3, padding=1),\n                nn.LeakyReLU(negative_slope=0.2, inplace=True)\n            )\n            self.layers.append(layer)\n            total_channels += out_channels\n        \n        # Local Feature Fusion\n        self.lff = nn.Conv2d(total_channels, in_channels, 1)\n    \n    def forward(self, x):\n        features = [x]\n        for layer in self.layers:\n            new_feature = layer(torch.cat(features, dim=1))\n            features.append(new_feature)\n        return x + self.lff(torch.cat(features, dim=1))\n\nclass UpsampleBlock(nn.Module):\n    def __init__(self, in_channels, scale_factor=2):\n        super(UpsampleBlock, self).__init__()\n        self.conv = nn.Conv2d(in_channels, in_channels * (scale_factor ** 2), 3, padding=1)\n        self.pixel_shuffle = nn.PixelShuffle(scale_factor)\n        self.activation = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n    \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.pixel_shuffle(x)\n        return self.activation(x)\n\nclass RealESRGAN(nn.Module):\n    def __init__(self, in_channels=3, base_channels=64, num_blocks=23, upscale_factor=4):\n        super(RealESRGAN, self).__init__()\n        \n        # Initial convolution with noise reduction capability\n        self.initial_noise_reduction = nn.Sequential(\n            nn.Conv2d(in_channels, base_channels//2, kernel_size=3, padding=1),\n            nn.LeakyReLU(negative_slope=0.2),\n            nn.Conv2d(base_channels//2, base_channels, kernel_size=3, padding=1),\n            nn.LeakyReLU(negative_slope=0.2)\n        )\n        \n        # Initial feature extraction\n        self.first_conv = nn.Conv2d(base_channels, base_channels, 3, padding=1)\n        \n        # Residual blocks\n        self.residual_blocks = nn.ModuleList([\n            ResidualDenseBlock(base_channels) for _ in range(num_blocks)\n        ])\n        \n        # Skip connection\n        self.skip_conv = nn.Conv2d(base_channels, base_channels, 3, padding=1)\n        \n        # Multiple upsampling stages for 4x scaling\n        self.upsample = nn.Sequential(\n            UpsampleBlock(base_channels, scale_factor=2),\n            UpsampleBlock(base_channels, scale_factor=2)\n        )\n        \n        # Final refinement conv\n        self.refinement = nn.Sequential(\n            nn.Conv2d(base_channels, base_channels//2, 3, padding=1),\n            nn.LeakyReLU(negative_slope=0.2),\n            nn.Conv2d(base_channels//2, in_channels, 3, padding=1)\n        )\n    \n    def forward(self, x):\n        # Initial noise reduction\n        x = self.initial_noise_reduction(x)\n        \n        # Initial feature extraction\n        features = self.first_conv(x)\n        skip = features\n        \n        # Residual blocks\n        for block in self.residual_blocks:\n            features = block(features)\n        \n        # Skip connection\n        features += self.skip_conv(skip)\n        \n        # Upsampling\n        features = self.upsample(features)\n        \n        # Final refinement\n        return self.refinement(features)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T08:12:22.292054Z","iopub.execute_input":"2024-12-16T08:12:22.292341Z","iopub.status.idle":"2024-12-16T08:12:22.305059Z","shell.execute_reply.started":"2024-12-16T08:12:22.292316Z","shell.execute_reply":"2024-12-16T08:12:22.304306Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, criterion, optimizer, \n                num_epochs=10, device=None, patience=5, \n                models_dir='/kaggle/working/models'):\n    \n    device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = model.to(device)\n    \n    # Learning rate scheduler\n    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, \n                                   patience=2, verbose=True)\n    \n\n    train_losses = []\n    val_losses = []\n    best_val_loss = float('inf')\n    epochs_no_improve = 0\n    \n    \n    os.makedirs(models_dir, exist_ok=True)\n    \n    # Training loop\n    for epoch in range(num_epochs):\n        \n        model.train()\n        train_loss = 0.0\n        \n        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n        for noisy, gt in progress_bar:\n            # Move data to device\n            noisy = noisy.to(device)\n            gt = gt.to(device)\n            \n            # Zero gradients\n            optimizer.zero_grad()\n            \n            # Forward pass\n            outputs = model(noisy)\n            \n            # Compute loss\n            loss = criterion(outputs, gt)\n            \n            # Backward pass\n            loss.backward()\n            \n            # Optimize\n            optimizer.step()\n            \n            # Update progress bar and track loss\n            train_loss += loss.item()\n            progress_bar.set_postfix({'Loss': loss.item()})\n        \n        # Average training loss for epoch\n        avg_train_loss = train_loss / len(train_loader)\n        train_losses.append(avg_train_loss)\n        \n        \n        model.eval()\n        val_loss = 0.0\n        \n        with torch.no_grad():\n            for noisy, gt in tqdm(val_loader, desc='Validation'):\n                noisy = noisy.to(device)\n                gt = gt.to(device)\n                \n                outputs = model(noisy)\n                loss = criterion(outputs, gt)\n                \n                val_loss += loss.item()\n        \n        # Average validation loss\n        avg_val_loss = val_loss / len(val_loader)\n        val_losses.append(avg_val_loss)\n        \n        # Learning rate scheduling\n        scheduler.step(avg_val_loss)\n        \n        # Print epoch summary\n        print(f'Epoch {epoch+1}/{num_epochs}:')\n        print(f'Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n        \n        # Model checkpointing\n        if avg_val_loss < best_val_loss:\n            best_val_loss = avg_val_loss\n            epochs_no_improve = 0\n            \n            # Save best model\n            best_model_path = os.path.join(models_dir, 'i_model.pth')\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'train_losses': train_losses,\n                'val_losses': val_losses,\n                'best_val_loss': best_val_loss\n            }, best_model_path)\n            print(f'Saved new best model with val loss: {best_val_loss:.4f}')\n        else:\n            epochs_no_improve += 1\n        \n        # Early stopping\n        if epochs_no_improve >= patience:\n            print(f'Early stopping triggered after {epoch+1} epochs')\n            break\n        \n        # Visualize training progress\n        plt.figure(figsize=(10, 5))\n        plt.plot(train_losses, label='Training Loss')\n        plt.plot(val_losses, label='Validation Loss')\n        plt.title('Training and Validation Loss')\n        plt.xlabel('Epoch')\n        plt.ylabel('Loss')\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(os.path.join(models_dir, 'loss_plot.png'))\n        plt.close()\n    \n    # Save final model\n    final_model_path = os.path.join(models_dir, 'final_model.pth')\n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'train_losses': train_losses,\n        'val_losses': val_losses\n    }, final_model_path)\n    \n    return model, train_losses, val_losses","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T08:12:22.306218Z","iopub.execute_input":"2024-12-16T08:12:22.306488Z","iopub.status.idle":"2024-12-16T08:12:22.319790Z","shell.execute_reply.started":"2024-12-16T08:12:22.306464Z","shell.execute_reply":"2024-12-16T08:12:22.319176Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"#Dataset dir\ntrain_train_dir = \"/kaggle/input/enhance-the-dark-world/archive/train/train\"\ntrain_gt_dir = \"/kaggle/input/enhance-the-dark-world/archive/train/gt\"\nval_val_dir = \"/kaggle/input/enhance-the-dark-world/archive/val/val\"\nval_gt_dir = \"/kaggle/input/enhance-the-dark-world/archive/val/gt\"\ntest_dir = \"/kaggle/input/enhance-the-dark-world/archive/test\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T08:12:22.320801Z","iopub.execute_input":"2024-12-16T08:12:22.321459Z","iopub.status.idle":"2024-12-16T08:12:22.333405Z","shell.execute_reply.started":"2024-12-16T08:12:22.321421Z","shell.execute_reply":"2024-12-16T08:12:22.332528Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_dataset = LowDimDataset(train_train_dir, train_gt_dir, transform=transform)\nval_dataset = LowDimDataset(val_val_dir, val_gt_dir, transform=transform)\ntest_dataset = LowDimDataset(test_dir, transform=transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T08:12:22.334379Z","iopub.execute_input":"2024-12-16T08:12:22.334704Z","iopub.status.idle":"2024-12-16T08:12:22.381056Z","shell.execute_reply.started":"2024-12-16T08:12:22.334669Z","shell.execute_reply":"2024-12-16T08:12:22.380492Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T08:12:22.381870Z","iopub.execute_input":"2024-12-16T08:12:22.382102Z","iopub.status.idle":"2024-12-16T08:12:22.386346Z","shell.execute_reply.started":"2024-12-16T08:12:22.382079Z","shell.execute_reply":"2024-12-16T08:12:22.385423Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"model = RealESRGAN(in_channels=3, base_channels=64, num_blocks=23, upscale_factor=4)\n# loss function\ncriterion = nn.MSELoss()\n\n# optimizer\noptimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T08:12:22.387322Z","iopub.execute_input":"2024-12-16T08:12:22.387560Z","iopub.status.idle":"2024-12-16T08:12:22.483663Z","shell.execute_reply.started":"2024-12-16T08:12:22.387536Z","shell.execute_reply":"2024-12-16T08:12:22.483050Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Train the model\ntrained_model, train_losses, val_losses = train_model(\n    model=model,\n    train_loader=train_loader,\n    val_loader=val_loader,\n    criterion=criterion,\n    optimizer=optimizer,\n    num_epochs=15,\n    patience=5\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T08:12:22.484588Z","iopub.execute_input":"2024-12-16T08:12:22.484923Z","iopub.status.idle":"2024-12-16T09:35:07.401908Z","shell.execute_reply.started":"2024-12-16T08:12:22.484886Z","shell.execute_reply":"2024-12-16T09:35:07.401190Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\nEpoch 1/15: 100%|██████████| 1105/1105 [05:22<00:00,  3.43it/s, Loss=0.000245]\nValidation: 100%|██████████| 267/267 [00:28<00:00,  9.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/15:\nTrain Loss: 0.0009, Val Loss: 0.0002\nSaved new best model with val loss: 0.0002\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/15: 100%|██████████| 1105/1105 [05:06<00:00,  3.60it/s, Loss=0.000323]\nValidation: 100%|██████████| 267/267 [00:25<00:00, 10.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/15:\nTrain Loss: 0.0004, Val Loss: 0.0002\nSaved new best model with val loss: 0.0002\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/15: 100%|██████████| 1105/1105 [05:06<00:00,  3.60it/s, Loss=0.000461]\nValidation: 100%|██████████| 267/267 [00:25<00:00, 10.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/15:\nTrain Loss: 0.0004, Val Loss: 0.0002\nSaved new best model with val loss: 0.0002\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/15: 100%|██████████| 1105/1105 [05:08<00:00,  3.58it/s, Loss=0.000269]\nValidation: 100%|██████████| 267/267 [00:25<00:00, 10.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/15:\nTrain Loss: 0.0004, Val Loss: 0.0002\nSaved new best model with val loss: 0.0002\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/15: 100%|██████████| 1105/1105 [05:07<00:00,  3.59it/s, Loss=0.000247]\nValidation: 100%|██████████| 267/267 [00:25<00:00, 10.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/15:\nTrain Loss: 0.0004, Val Loss: 0.0002\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/15: 100%|██████████| 1105/1105 [05:07<00:00,  3.60it/s, Loss=0.000289]\nValidation: 100%|██████████| 267/267 [00:25<00:00, 10.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/15:\nTrain Loss: 0.0003, Val Loss: 0.0002\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/15: 100%|██████████| 1105/1105 [05:02<00:00,  3.65it/s, Loss=0.000177]\nValidation: 100%|██████████| 267/267 [00:24<00:00, 10.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/15:\nTrain Loss: 0.0004, Val Loss: 0.0002\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/15: 100%|██████████| 1105/1105 [05:02<00:00,  3.66it/s, Loss=0.000154]\nValidation: 100%|██████████| 267/267 [00:24<00:00, 11.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/15:\nTrain Loss: 0.0003, Val Loss: 0.0002\nSaved new best model with val loss: 0.0002\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/15: 100%|██████████| 1105/1105 [05:02<00:00,  3.65it/s, Loss=0.000479]\nValidation: 100%|██████████| 267/267 [00:24<00:00, 10.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/15:\nTrain Loss: 0.0003, Val Loss: 0.0002\nSaved new best model with val loss: 0.0002\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/15: 100%|██████████| 1105/1105 [05:02<00:00,  3.65it/s, Loss=0.000228]\nValidation: 100%|██████████| 267/267 [00:24<00:00, 10.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/15:\nTrain Loss: 0.0003, Val Loss: 0.0002\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/15: 100%|██████████| 1105/1105 [05:02<00:00,  3.66it/s, Loss=0.000228]\nValidation: 100%|██████████| 267/267 [00:24<00:00, 11.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11/15:\nTrain Loss: 0.0003, Val Loss: 0.0002\nSaved new best model with val loss: 0.0002\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/15: 100%|██████████| 1105/1105 [05:02<00:00,  3.65it/s, Loss=0.000346]\nValidation: 100%|██████████| 267/267 [00:24<00:00, 10.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12/15:\nTrain Loss: 0.0003, Val Loss: 0.0002\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/15: 100%|██████████| 1105/1105 [05:03<00:00,  3.65it/s, Loss=0.000402]\nValidation: 100%|██████████| 267/267 [00:24<00:00, 10.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13/15:\nTrain Loss: 0.0003, Val Loss: 0.0002\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/15: 100%|██████████| 1105/1105 [05:02<00:00,  3.65it/s, Loss=0.000301]\nValidation: 100%|██████████| 267/267 [00:24<00:00, 11.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14/15:\nTrain Loss: 0.0003, Val Loss: 0.0002\nSaved new best model with val loss: 0.0002\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/15: 100%|██████████| 1105/1105 [05:03<00:00,  3.64it/s, Loss=0.000383]\nValidation: 100%|██████████| 267/267 [00:24<00:00, 10.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15/15:\nTrain Loss: 0.0003, Val Loss: 0.0002\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T09:35:07.402985Z","iopub.execute_input":"2024-12-16T09:35:07.403290Z","iopub.status.idle":"2024-12-16T09:35:07.407596Z","shell.execute_reply.started":"2024-12-16T09:35:07.403264Z","shell.execute_reply":"2024-12-16T09:35:07.406802Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"output_dir = \"/kaggle/working/test_gt\"\nos.makedirs(output_dir, exist_ok=True)\n\nmodel.eval()\nwith torch.no_grad():\n    for idx, noisy in enumerate(test_loader):\n        noisy = noisy.to(device)\n        outputs = model(noisy)\n        image_name = f\"gt_{idx+1:05d}.png\"  # Image name\n        save_image(outputs, os.path.join(output_dir, image_name))\n        #print(f\"Saved image: {image_name}\")  # Print image name\nprint('All Images saved in .png format')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T09:35:07.408613Z","iopub.execute_input":"2024-12-16T09:35:07.408833Z","iopub.status.idle":"2024-12-16T09:35:29.523466Z","shell.execute_reply.started":"2024-12-16T09:35:07.408812Z","shell.execute_reply":"2024-12-16T09:35:29.522574Z"}},"outputs":[{"name":"stdout","text":"All Images saved in .png format\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"def images_to_csv(folder_path, output_csv):\n    data_rows = []\n    for filename in sorted(os.listdir(folder_path)):\n        if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n            image_path = os.path.join(folder_path, filename)\n            image = Image.open(image_path).convert('L')\n            #print(image.size)\n            image_array = np.array(image).flatten()[::8]\n            #print(image_array.shape)\n            # Replace 'test_' with 'gt_' in the ID\n            image_id = filename.split('.')[0]\n            data_rows.append([image_id, *image_array])\n    column_names = ['ID'] + [f'pixel_{i}' for i in range(len(data_rows[0]) - 1)]\n    df = pd.DataFrame(data_rows, columns=column_names)\n    df.to_csv(output_csv, index=False)\n    print(f'Successfully saved to {output_csv}')\n\nfolder_path = '/kaggle/working/test_gt'\noutput_csv = 'submission.csv'\nimages_to_csv(folder_path, output_csv)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T09:35:29.526856Z","iopub.execute_input":"2024-12-16T09:35:29.527214Z","iopub.status.idle":"2024-12-16T09:36:11.200929Z","shell.execute_reply.started":"2024-12-16T09:35:29.527158Z","shell.execute_reply":"2024-12-16T09:36:11.200079Z"}},"outputs":[{"name":"stdout","text":"Successfully saved to submission.csv\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"sub = pd.read_csv(\"/kaggle/working/submission.csv\")\nsub.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T09:36:11.202383Z","iopub.execute_input":"2024-12-16T09:36:11.202705Z","iopub.status.idle":"2024-12-16T09:36:15.471092Z","shell.execute_reply.started":"2024-12-16T09:36:11.202678Z","shell.execute_reply":"2024-12-16T09:36:15.470375Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"         ID  pixel_0  pixel_1  pixel_2  pixel_3  pixel_4  pixel_5  pixel_6  \\\n0  gt_00001       35       57       59       48       52       56       48   \n1  gt_00002       26       38       45       50       50       44       38   \n2  gt_00003       25       38       38       36       38       36       34   \n3  gt_00004       31       58       62       61       63       68       78   \n4  gt_00005       20       25       27       29       26       25       24   \n\n   pixel_7  pixel_8  ...  pixel_81910  pixel_81911  pixel_81912  pixel_81913  \\\n0       45       47  ...           28           28           28           28   \n1       35       40  ...           33           33           36           37   \n2       37       42  ...           33           35           38           38   \n3       99       98  ...           42           42           42           41   \n4       25       24  ...           51           48           47           47   \n\n   pixel_81914  pixel_81915  pixel_81916  pixel_81917  pixel_81918  \\\n0           27           26           28           28           28   \n1           36           34           33           34           36   \n2           36           36           39           39           39   \n3           41           43           43           42           43   \n4           50           50           51           52           51   \n\n   pixel_81919  \n0           27  \n1           36  \n2           36  \n3           43  \n4           49  \n\n[5 rows x 81921 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>pixel_0</th>\n      <th>pixel_1</th>\n      <th>pixel_2</th>\n      <th>pixel_3</th>\n      <th>pixel_4</th>\n      <th>pixel_5</th>\n      <th>pixel_6</th>\n      <th>pixel_7</th>\n      <th>pixel_8</th>\n      <th>...</th>\n      <th>pixel_81910</th>\n      <th>pixel_81911</th>\n      <th>pixel_81912</th>\n      <th>pixel_81913</th>\n      <th>pixel_81914</th>\n      <th>pixel_81915</th>\n      <th>pixel_81916</th>\n      <th>pixel_81917</th>\n      <th>pixel_81918</th>\n      <th>pixel_81919</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>gt_00001</td>\n      <td>35</td>\n      <td>57</td>\n      <td>59</td>\n      <td>48</td>\n      <td>52</td>\n      <td>56</td>\n      <td>48</td>\n      <td>45</td>\n      <td>47</td>\n      <td>...</td>\n      <td>28</td>\n      <td>28</td>\n      <td>28</td>\n      <td>28</td>\n      <td>27</td>\n      <td>26</td>\n      <td>28</td>\n      <td>28</td>\n      <td>28</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gt_00002</td>\n      <td>26</td>\n      <td>38</td>\n      <td>45</td>\n      <td>50</td>\n      <td>50</td>\n      <td>44</td>\n      <td>38</td>\n      <td>35</td>\n      <td>40</td>\n      <td>...</td>\n      <td>33</td>\n      <td>33</td>\n      <td>36</td>\n      <td>37</td>\n      <td>36</td>\n      <td>34</td>\n      <td>33</td>\n      <td>34</td>\n      <td>36</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>gt_00003</td>\n      <td>25</td>\n      <td>38</td>\n      <td>38</td>\n      <td>36</td>\n      <td>38</td>\n      <td>36</td>\n      <td>34</td>\n      <td>37</td>\n      <td>42</td>\n      <td>...</td>\n      <td>33</td>\n      <td>35</td>\n      <td>38</td>\n      <td>38</td>\n      <td>36</td>\n      <td>36</td>\n      <td>39</td>\n      <td>39</td>\n      <td>39</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>gt_00004</td>\n      <td>31</td>\n      <td>58</td>\n      <td>62</td>\n      <td>61</td>\n      <td>63</td>\n      <td>68</td>\n      <td>78</td>\n      <td>99</td>\n      <td>98</td>\n      <td>...</td>\n      <td>42</td>\n      <td>42</td>\n      <td>42</td>\n      <td>41</td>\n      <td>41</td>\n      <td>43</td>\n      <td>43</td>\n      <td>42</td>\n      <td>43</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>gt_00005</td>\n      <td>20</td>\n      <td>25</td>\n      <td>27</td>\n      <td>29</td>\n      <td>26</td>\n      <td>25</td>\n      <td>24</td>\n      <td>25</td>\n      <td>24</td>\n      <td>...</td>\n      <td>51</td>\n      <td>48</td>\n      <td>47</td>\n      <td>47</td>\n      <td>50</td>\n      <td>50</td>\n      <td>51</td>\n      <td>52</td>\n      <td>51</td>\n      <td>49</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 81921 columns</p>\n</div>"},"metadata":{}}],"execution_count":15}]}